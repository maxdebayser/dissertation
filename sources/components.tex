In this chapter, we give a precise definition of several concepts that will be used later in this dissertation, and
establish the relations between them. It is often the case that words that denote intangible things, such as concepts, are vague
and can have slightly different interpretations for different persons or in different contexts. The most representative example
of this is the term \emph{object} that, even restricted to the field of computer science, supports many different interpretations.
In many cases this vagueness is a good thing because the human intellect is able to adapt the intuitive notion behind a word
to different usages. For instance, even if object orientation manifests itself in many different forms in different programming
languages, we are still able to recognize the same idea. However, in order to develop the ideas of the forthcoming chapters
without ambiguity, we need to tie a few terms to very specific meanings. \emph{Component}, \emph{module}, \emph{service} and
\emph{library} are such words for which we will give precise definitions. But, before we delve into the details of those
definitions we will first analyze why coarse grained units of reuse are needed.

In the history of programming, there has always existed the desire to reuse existing work. In other words, designers have always
striven to reduce the waste of programming effort. In 1968, McIlroy advocated that to turn the building of software into a truly
industrial activity there should be a way of building applications by composing pieces of software available on the marketplace
\cite{McIlroy}. The key, in his vision, was a concept called software components, in analogy to hardware components. Also in
analogy to electrical and mechanical engineering, there should be a wiring standard that would make the third-party composition
of software possible. Although it is questionable if software could ever be mass-produced, it is clear that there is a need for
tools and standards that effectively supports code reuse by independent developers.

In the beginning, when there were no high-level languages, it was difficult to reuse code because it was tightly coupled to a
specific machine, and there were only rudimentary tools to compose independently developed pieces of software.
With procedural languages, small, encapsulated units of code called procedures were introduced with standardized calling
conventions, making separate compilation possible. In addition, these procedures could now be ported to all other computer platforms
that had a compiler for this language. However, procedures were too fine-grained entities to be distributed and reused independently.
Procedures often depend on definitions of data types and on other procedures but these dependencies are implicit, buried in their
encapsulated implementation. It would be a lot of work for an application builder to take hundreds of packages containing single procedures and
compose. For this reason procedures had to be grouped in large libraries.

Then came object-oriented programming encapsulating data structures and procedures behind well defined interfaces. It was thought that
objects would revolutionize reuse by allowing one to build an application entirely out of pre-defined, loosely coupled, objects. 
Object orientation was indeed very successful and objects such as supported by most programming languages can be used to model
entities going from the granularity of employee records to huge subsystems. But it is precisely this lack of syntactical distinction and
of distinct tooling support that makes it difficult to use objects as units of third-party reuse and composition. Normally, the programmer is
free to randomly assign class definitions to modules and there is no way of expressing the dependencies between subsystems
at a higher level than module dependencies that are resolved by the linker.

This was a very unsatisfactory state of affairs as concepts from object orientation, such as separation of interface and implementation,
and Liskov's substitution principle fitted perfectly into McIlroy's vision of software components \cite{Liskov}. However, object-orientation
has not failed, as is sometimes said \cite{Udell}, rather it was mistakenly seen as the solution for the reuse problem. As expressed by Knoernschild
\cite{Knoernschild},

\begin{quotation}
``We need to break away from the thinking that objects help us create more reusable software.
Instead, objects help us create more extensible software, which is an enabler of reuse.''
\end{quotation}

Individual classes cannot be units of reuse because they are too fine-grained to be independently released and deployed. This
is nicely summarized in the Reuse/Release principle: \emph{The unit of reuse is the unit of release} \cite{Martin}.
Consequently, in the 1990's several attempts were made to create coarse-grained units of software with object-oriented interfaces,
that could be units of release. These units are called \emph{software components} and are built on the ideas of object-orientation,
software modules and services. Thus in the remainder of this chapter we will first go through the definitions of modules in section
\ref{sec:modules}, and services in section \ref{sec:services}, to establish them as basic constructs that can be used to build
component standards. Libraries are covered in \ref{sec:libraries}, as they share the primordial motivation of software reuse but
are an essentially different concept. The chapter ends with Section \ref{sec:components} covering modern definitions of software
components and presenting some of the most important component technologies available.


\section{Modules}
\label{sec:modules}

Modules make it possible to partition a program into smaller parts that can be developed independently and assembled.
A good description of the motivation for modular programming can be found in Parnas \cite{Parnas}

\begin{quotation}
``The benefits expected of modular programming are:
(1) managerial - development time should be shortened because separate groups would work on each module with little need for communication;
(2) product flexibility - it should be possible to make drastic changes to one module without a need to change others;
(3) comprehensibility - it should be possible to study the system one module at a time. The whole system can therefore be better designed because it is better understood.''
\end{quotation}

Although this lucidly states why modules are important, it doesn't really describe what they are. A more complete
definition was given by Knoernschild \cite{Knoernschild}:

\begin{quotation}
``A module is a deployable, manageable, natively reusable, composable, stateless unit of software that provides a concise interface to consumers''
\end{quotation}

Modules are deployable because they are physical packages of code. The details vary depending on the programming language but modules are
always meant for local loading into a process and therefore come in a format that is understood by the machine or interpreter that is
executing the process. This is what is meant by native use. They are stateless because they are just the binary representation of the
code that is brought to life during execution. In a way, modules are the persistent storage equivalent of the read-only instruction
memory space of the Harvard architecture.

But the most important aspect of modules is that they are composable, providing a mechanism to delay the binding of entities to its consumers
to a point in time after the compilation is finished. As Szyperski \cite{Szyperski} put it,

\begin{quotation}
``An important hallmark of truly modular approaches is the support of separate compilation, including the ability
to type-check across module boundaries properly.'' %Szyperski pg 39.
\end{quotation}

This is possible precisely because modules provide the specification of an interface that instructs the compiler how an entity must be used. As long
as the compiler generates code that follows this usage specification, the actual linking need only be done when these entities are actually required
during execution.

Because modules can be composed after their compilation, they can be developed by independent teams as long as their interface doesn't change.
This also makes modules an important managerial tool to partition the development of a software product,

An important consequence of the separation of compilation units is that the same module can be used to build different software products if it's
contents are useful in more than one context. This feature makes modules the basic unit of native reuse. 

It is easy to extend the meaning of the term module to include concepts such as components or objects, but this overly broad concept
would only lead to confusion and to a lack of precision of our definitions. Indeed, as Szyperski noted, ``...modules can be used, and
always have been used, to package multiple entities, such as ADTs or, indeed, classes, into one unit. Also modules do not have a concept
of instantiation, whereas classes do''

Modules in \texttt{C/C++} are object files, static or dynamic libraries and executables. In Java modules are represented by the JAR file format and
its variants, WAR and EAR files. The problem with Java modules is that they provide no truly effective mechanisms of encapsulation. All classes, even
internal implementation classes in the \texttt{classpath} are globally visible. In addition it is difficult to trace dependencies between JAR files
because classes can refer to any other class visible in this global name space. The \texttt{OSGi} framework was created to remedy this situation,
enforcing visibility restrictions and managing the dependencies on a JAR file level \cite{Hall}.


% pesquisar modula-2 ?

%Modules are used to encapsulate design decisions. Repository mining can be used to find out where bad modularization causes changes in one
%module to propagate to others. % isso é relevante?


\section{Libraries}
\label{sec:libraries}

A library is a stateless collection of reusable, fine-grained entities such as procedures and classes, put together in a single package. These entities could be reused
and delivered individually but the cost of managing a high number of modules would be too high. The use of libraries is always local and intra-process, using the linking
mechanism of modules.

An essential difference between libraries and modules is that libraries have no representation in the language. Even in language with primitive modularity
resources, there are elements in the language provided to control aspects of the resulting module, such as the visibility of symbols.

Libraries allow a separation of interface and implementation, the former usually called \emph{Application Programming Interface} (\texttt{API}). There are many examples
of a standardized \texttt{APIs} that have many implementations such as the \texttt{OpenGL} graphics library. To a certain extent, libraries enable late-binding but not
as much as object-oriented polymorphism would allow. Programs don't usually select a specific version of a library at runtime and its not possible to load more than
one implementation of a library at once. In addition libraries are only replaceable without recompilation of its clients if their binary interface, also called
\emph{Application Binary Interface} (\texttt{ABI}), remains the same despite internal differences. Libraries are also stateless; it would make no sense to load a library
more than once in the same process. There are no instances of libraries.

In general, the procedures or classes in a library are not randomly thrown together. They are assembled in one package because they all deal with the same problem domain.
Libraries are most successfully employed to achieve code reuse across horizontal domains. Most widely used libraries address problems that are common to many applications.
For example, the \texttt{BLAS} linear algebra package, the \texttt{Hibernate} library and the \texttt{Qt} windowing library are used in many different context because they
contain infrastructure code that is independent of any specific application domain. In contrast, it is difficult to see libraries that contain a generic class modeling employees
because each organization is likely to have different requirements for such a class.

Libraries are a natural consequence of modules and separate compilation and appeared mostly at the same time. Because the same collection of horizontal utilities
could be used in many applications in the same system, it made sense to install pre-compiled modules.

\section{Services}
\label{sec:services}

The notion of a service incorporates a pattern of control flow. A service is always reactive, responding to requests of a client process. In some cases,
services can call a client using a callback mechanism, but the initiator of the dialogue is always the client. An essential property of services is a
separation of interface and implementation akin to polymorphism in object oriented languages. A service is a runtime entity and has its own identity.
The same process can use several individual services that implement the same interface. For example, a process could read files from different file
servers, all providing the same set of operations.

Although in some cases it is convenient to use the term service to describe an object or an architectural unit within a process that is used in
a reactive manner, we will add two more requirements to our definition of service to prevent unnecessary confusion.

The first requirement is that a service should be accessible through some form of inter-process communication (IPC). For example, a local printing service
could be invoked by placing the documents to print in a certain location in the filesystem. The second requirement is that any individual service
should have a location transparent identifier, an URL.

These two requirements allow us to establish services as a primary form of inter-process code reuse. Services are deployed only once and can be used
by many clients within an organization.

Services are particularly useful as building blocks of large enterprise systems where procedures must follow work flows that involve retrieving data
from a centralized database system, billing external organizations and so on. The individual services are in many cases re-used in more than one
application. For example, the employee database service could be consulted both by a human resources application or an accounting application.
This kind of architecture is known as \emph{Service Oriented Architecture (SOA)}.

Due to the cost of \texttt{IPC} operations, services tend to provide coarse grained operations that do a lot of work to compensate for the invocation
overhead.

Although our definition allows any \texttt{IPC} mechanism to be used, in this discussion, whenever we use the term service, we will be referring to
services accessible using a \emph{Remote Procedure Call (RPC)} or \emph{Remote Method Invocation (RMI)} abstraction.

Despite being conceptually unrelated, services are necessarily packaged and deployed using modules and this has important consequences on the
reusability of services. If more than one service implementation is packaged in the same module, one cannot be used without including the other
and its dependencies. Also if a service is called through \texttt{RMI}, the interface classes cannot be put in the same module as the implementation,
as this would force clients to depend on the module of a specific implementation, even if they use another one.

% Services have to be coarse grained and specific to be both useful and efficient. But it makes them less reusable.
% Classes cannot be used directly as units to reuse the code of a service because they are not units of deployment.
% Code reuse of a service can only be achieved if it is designed in a modular way

\section{Components}
\label{sec:components}

As discussed in the introduction of this chapter, to achieve reuse we need coarse-grained units of release with an
explicit and abstract interface. Intuitively, what is needed is a concept that denotes a unit of both physical and
logical design. We will call those units \emph{software components}. As is the case with many other concepts,
the term \emph{software component} means slightly different things to different people. Perhaps the most general
definition, which encompasses the core notions behind components, is the one given by Grady Booch \cite{Booch87}:

\begin{quotation}
``A reusable software component is a logically cohesive, loosely coupled module that denotes a single abstraction''
\end{quotation}

A point of contention is the moment when the actual phase of composition takes place. Several authors view components as reusable source entities that
are integrated at build-time (at build-time there is no difference if the components are in source form or already in module form) \cite{Lakos}, some
insist that components should be assembled only at runtime \cite{Szyperski} \cite{Heineman}, and others feel that it is not worth to make this distinction
\cite{Czarnecki00} \cite{Sametinger}.

Although we feel personally more inclined to accept a more general definition of components, in this text we will use the one by Szyperski and Pfisters \cite{WCOP97}

\begin{quotation}
``A Software component is a unit of composition with contractually specified interfaces and explicit context dependencies only.
A software component can be deployed independently and is subject to composition by third parties.''
\end{quotation}

Even with all these carefully crafted definitions, the distinction between modules and components can become blurry if
we do no take care to insist that a component should be a logically cohesive unit, in other words, it should contain
a single abstraction. Without this requirement what remains is a specification for modules that are composed at runtime,
as exemplified by the following definition of \texttt{OSGi} modules: \cite{Hall}

\begin{quotation}
``\textbf{Module} A set of logically encapsulated implementation classes, an optional public \texttt{API} based on a subset
of the implementation classes, and a set of dependencies on external code.''
\end{quotation}

Although this definition agrees with most things we have said about components, the difference, of course, is that modules
are not required to contain code for a single unit of functionality. An \texttt{OSGi} module can be a loose collection of
classes, a library indeed, if it explicitly specifies what classes are part of its public \texttt{API} and on which other
modules it depends. As a matter of fact, \texttt{OSGi} has been used as an infrastructure for component frameworks in \texttt{Java}.

In addition, to be independently deployable, a component cannot be physically integrated in a larger software product at build-time
it must remain independent and be composed at runtime. This requirement means that, to support composition, we cannot rely on the
mechanisms provided by the compiler and the linker to check dependencies and compose modules. We must establish rules to reify these
dependencies and make components programmatically composable at runtime. 

First we require that the interaction between two connected components should happen through a well defined interface.
For component orientation to make sense at all, it should be possible to exchange a component in an application by another
one that has the same interface but a different implementation. In other words, components should follow Liskov's
Substitution Principle \cite{Liskov}.

If the interaction is based on method calls, there should be an abstract interface type that is implemented by the component responding
to method calls and known to the requesting component. If the interaction is based on streams of data, it should follow a protocol
that is known to both parties and to the external agent responsible for the composition.

The points of connection between components are called \emph{ports} and can be of two kinds. The first kind are ports used to
get access to a service that is provided by the component. The second kind is used by the component to interact with services
it depends on. We will adopt \texttt{CCM}'s nomenclature and use the terms \emph{facet} and and \emph{receptacle} for
``provides'' and ``requires'' ports, respectively \cite{CCM}. The general idea is that one component is connected to the other
by connecting a facet to a receptacle. Ports are always associated to an interface.

Although the general idea of these rules is simple, there are many ways of implementing them; the languages used to implement
components, the form of interaction, how interfaces are represented and implemented. For every one of those details there
are many possible choices of implementation. At the same time, it is essential that components conform to the same set of
rules to be able to interact. A set of these rules is called a \emph{component model}. This model implicitly defines an abstract
platform or environment suitable for executing these components. We will use the term \emph{component framework} for the
implementation of such a model.

These ideas are captured more precisely in the following definition by Council and Heineman \cite{Heineman}:

\begin{quotation}
``A software component is a software element that conforms to a component model and can be independently deployed and composed
without modification according to a composition standard.

A component model defines specific interaction and composition standards. A component model implementation is the dedicated
set of executable software elements required to support the execution of components that conform to the model.

A software component infrastructure is a set of interacting software components designed to ensure that a software system
or subsystem constructed using those components and interfaces will satisfy clearly defined performance specifications.''
\end{quotation}

An interesting example that predates the modern definition of software components and component model are \texttt{UNIX}
\emph{pipes and filters}. Filters are programs that communicate by streams of text data, while pipes are channels through
which the output of one filter can be directed to the input of another one. It is common to use program such as the \texttt{sed}
stream editor to adapt a streams content to the input protocol of another one. To construct more advanced behaviors, \texttt{shell}
command languages are commonly used as glue language. In addition, the individual filter programs are perfectly self-contained,
independently deployable and perform well defined tasks. The component infrastructure is the \texttt{UNIX} operating system itself.

However most of the ``canonical'' component models interact using object-oriented approaches. In some languages interface are elements
of the language, in others they are represented as abstract
base classes and components represent their facets as objects that implement these interfaces. Conversely, a receptacle
receive a reference to an object implementing the interface it expects and is then able to use it by the means of method calls.
In the case of intra-process components, a connection can be established by means of a reference to the facet object.
When \texttt{RMI} is used, the receptacle receives a reference to a \emph{stub} object that forwards the calls across an \texttt{IPC} channel. 

Local component frameworks are little more than a set of infrastructure utilities that perform the loading of components and their composition.
Remote component frameworks are typically more heavyweight, including implementations for one or more \texttt{RMI} protocols, component registries,
and so forth. Some frameworks go to the point of providing an entire environment that includes persistence and distributed transactions support.

Perhaps the most prominent example of a local component framework is \texttt{Microsoft's} \texttt{Component Object Model (COM)}, although
later remote components were introduced. It is, essentially, specification for binary interfaces. An interface is represented as a table of
pointers to methods. A facet is an object whose binary representation has a pointer to the method table representing its implemented interfaces.
It is not by chance that this scheme is precisely how Microsoft's \texttt{C++} compiler lays out polymorphic objects in memory.
In \texttt{COM}, every facet has to implement the interface \texttt{IUnknown} that contains methods for reference counting and a method
to obtain reference to other interfaces implemented by this component. In \texttt{COM}, interface and components are identified by
universally unique identifiers (UUID), 128-bit random numbers generated in a way to make clashing extremely unlikely.
When components are installed, factory objects are registered in a system registry using the component's UUID as a key.
When a program needs the functionality of a specific component, it locates a factory using this registry and instantiates the desired component.
The same mechanism is used for components that depend on other components, which means that component dependencies are not explicit
in \texttt{COM}. \texttt{COM} was the infrastructure used for the \texttt{Object Linking and Embedding (OLE)} technology that enables
things such as editing rich text using a word processor component inside a spreadsheet cell. \texttt{COM} is still being used
in a variety of services in Microsoft's operating system but is largely being superseded by the \texttt{.NET} framework for application
programming. Nonetheless, it has influenced many other component frameworks like Mozilla's \texttt{XPCOM} and \texttt{OpenCOM}, a component
framework for embedded applications \cite{XPCOM} \cite{OpenCOM01}.

Another good example of local components are Sun's JavaBeans technology. There are several component models supported by the Java platform, each
suited to a particular problem domain. JavaBeans are visual components that can be composed and configured in a visual development environment
to produce user interfaces. JavaBeans can be configured by changing the values of their properties, which, by convention are accessed by \emph{getter}
and \emph{setter} methods. JavaBeans can be sources or consumers of events and thus can be connected to each other. 

Sun's component frameworks are all based on the Java language and depend heavily on features of the JVM. The packaging of all Java components is
done using Java archive (JAR) files, that basically are compressed files containing class files and resources.

For the enterprise market, Sun introduced the Enterprise Java Beans (EJB) component framework. This specification includes several kinds of beans,
but the most important ones are the so-called session beans. Session beans are service components that run on an application server that provide
all the infrastructure needed to enable remote access using \texttt{Java RMI}. The EJB platform also includes directory, messaging, persistence and
transaction support services. The session beans model is not connection oriented. A bean that depends on other beans has to go through the
directory service to get a reference to the desired bean.

In addition to JavaBeans and EJB beans, there is the Java servlet specification. Java servlets are components that contain an implementation
of a server for some protocol, usually HTTP. Java servlets are usually packaged in WAR files, which are an extension to the JAR format
with a pre-defined standardized structure for the laying out web applications. These WAR files can be deployed directly in an application server.

The CORBA Component Model (CCM) is OMG's response to EJB and proposes a language-independent component model, compatible with EJB. CCM is built
on top of CORBA, a language independent standard for remote objects and remote method invocation \cite{CCM}. CCM extends CORBA's interface definition language
(IDL) to include the concept of component connectors such as facets and receptacles. Unlike EJB and COM, by enforcing explicit receptacles, support
a connection-oriented style of composition.

\section{Modularity Patterns and Packaging}
\label{sec:patterns}

Because the unit of reuse is the unit of release special care has to be put into packaging.
The relationship between modules is defined by the logical relationship of classes and procedures
and how they are assigned to physical units. If two related classes are assigned to different
modules, a physical dependency is created. There is a lot of literature on object-oriented design
that shows how to create extensible and reusable logical designs but few treat the physical design
that must be considered to make reuse possible. This section is based on the work of Szyperski
\cite{Szyperski}, \cite{Lakos}, \cite{Martin} and \cite{Knoernschild}. \emph{Packaging} is also called
\emph{physical design} by Knoernschild, so both terms are used interchangeably in this text.

Creating units of independent reuse and deployment is not an easy task. The more flexible and
configurable a unit of reuse is, the more difficult it is to use because more decisions are
delegated to the user. In the same way, a coarse-grained physical unit is easier to use
but also less flexible because its impossible to  use only a small part of it. These 
conflicting concerns are well summarized in Szyperski's statement:

\begin{quotation}
``Maximizing reuse minimizes use'' 
\end{quotation}

Most of the time, there are no hard rules that can be followed to create code that is both reusable
and easy to use. The engineer has to find the best trade-off between these conflicting requirements.
However there are principles that can be followed that lead to good designs.
In his book, Java Application Architecture, Knoernschild listed a series of physical
design patterns or guidelines for sound physical design. Although his guidelines are directed
at module design, his concept of modules is very close to Szyperski's notion of software components,
and actually his principles are even more important when applied to components.

\textbf{External Configuration}:
Modules and components often need information that instructs them
on how to interact with their environment. For example, modules often build on the functionality
of other modules. But often the information of which external module to use is hard-coded as
is often the case with libraries that use other libraries. To create really independently reusable
components that have no implicit dependencies on their environment we need to move these
from hard-coded information to implicit configuration that can be externally controlled.
The same applies to other kinds of information. For example, a logging component should not
write its output to a fixed location but rather allow this location to be configured externally.
External configuration allows a wider range of behaviors of component making it potentially
more useful.

There are several ways of allowing for external configuration. It could be done with configuration
files, but it is difficult to do this without making several assumptions on the environment, such as
the existence of a file system, and a specific path in that filesystem. It is best to provide a
programmatic interface for external configuration. In Chapter \ref{chap:ioc}, we discuss a better
way to do this.

\textbf{Cohesion}:
This pattern states that modules should be functionally cohesive. Classes that are used together should
be put in the same module. Conversely, unrelated classes belong in different modules. Cohesion has several
advantages. Cohesive modules are easier to understand because they have a single, well defined role in a
larger system. Also, with a better understanding comes a better maintainability. Cohesive module also tend
to have fewer dependencies. As random functionality is thrown into a single module, chances are that each
functionality introduces dependencies to external modules. When a module with low cohesion is used, it is
likely that only a small subset of its functionality is needed. However as a consequence of the common reuse
principle \cite{Martin}, the use of a part of a module forces the inclusion of all external dependencies.
This complicates deployment as several external modules must be installed as well, even if they are only
required by parts of modules that are not used.

\textbf{Independent deployment}:
The most reusable module or component is one that can be deployed without requiring the deployment of any other
modules. Of course this is not always possible, but one should try to minimize outgoing dependencies.
If a lot of functionality is put into a module to minimize its dependencies, cohesion will suffer.
The key is to find a balance between the two concerns.

\textbf{Acyclic relationships}:
Relationship between modules should always be acyclic. Modules that are part of a cycle of dependencies
must always be deployed together, pretty much defeating the purpose of modularizing code in the first place.
Cyclic dependencies are induced by cyclic class dependencies and can be broken using the techniques of
\emph{demotion} and \emph{escalation} \cite{Lakos}

\textbf{Container Independence}:
Modules should be as independent on their runtime container as possible. Modules that depend heavily on their
container are not portable to other runtime environments. In addition it can be difficult to effectively
test modules with strong container coupling. This guideline is sometimes difficult to achieve because
programming frameworks often impose a strong coupling. As an example, components that are built on top
of CCM must inherit from abstract bases classes generated by CCM's tools. As inheritance is the strongest coupling
these components are difficult to port to other platforms. Container independence requires abstracting the
runtime environment away. In Chapters \ref{chap:ioc} and \ref{chap:sca}, we treat this issue in depth.

\textbf{Published Interface}:
The public interface of a module should be well known. Conversely, internal implementation classes
should always be encapsulated. While this is not mandatory for modules, it is one of the defining
traits of software components.

\textbf{Separate Abstraction}:
This pattern states that the abstract interface of a module and its implementation should be put in separate modules.
This is essential if we want to allow alternative implementations of an abstraction. If the interface and one implementation
are packaged together, it is still possible to plug another implementation into the client modules but now two implementations
must be deployed together with their dependencies. This pattern is essential for component frameworks that use interfaces to express service contract.

\textbf{Abstract Module}:
This pattern states that one module should only depend on the abstract interface of other modules. Depending directly on
concrete classes couples a module unnecessarily to a fixed implementation, whereas depending on abstract classes allows
to plug alternative implementation. Ideally a module should only depend on pure interface modules as resulting from the
application of the Separate Abstraction pattern. However, this pattern introduces a significant difficulty. A module
can only use abstract references to objects but behind those references are objects of concrete implementation classes.
It cannot instantiate these because this would couple the module to the concrete implementation classes. This problem
is a crucial one, nevertheless, and chapter \ref{chap:ioc} is entirely devoted to this subject.

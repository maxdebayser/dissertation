\section{Introduction}

In this chapter we hope to give a precise definition of several concepts that will be used later in this dissertation, and to
establish the relations between them. It is often the case that words that denote intangible things such as concepts are vague
and can have slightly different interpretations for different persons or in different contexts. The most representative example
of this is the term \emph{object} that, even restricted to the field of computer science, supports many different interpretations.
In many cases this vagueness is a good thing because the human intellect is able to adapt the intuitive notion behind a word
to different usages. For instance, even if object orientation manifests itself in many different forms in different programming
languages, we are still able to recognize the same idea. However, in order to develop the ideas of the forthcoming chapters
without ambiguity we need to tie a few terms to very specific meanings. \emph{Component}, \emph{module}, \emph{service} and
\emph{library} are such words for which we will try to give precise definitions. But before we delve into the details of those
definitions we will first analyze why coarse grained units of reuse are needed.

In the history of programming, there has always existed the desire to reuse existing work. In other words, designers have always
striven to reduce the waste of programming effort. In 1968 McIlroy proposed that to turn the building of software into a truly
industrial activity there should be a way of building applications by composing pieces of software available on the marketplace
\cite{McIlroy}. The key, in his vision, was a concept called software components, in analogy to hardware components. Also in
analogy to electrical and mechanical engineering there should be a wiring standard that would make the third-party composition
of software possible. Although it is questionable if software could ever be mass-produced, it is clear that there is a need for
tools and standards that effectively supports code reuse by independent developers.

In the beginning, when there were no high-level languages it was difficult to reuse code because it was tightly coupled to a
specific machine and there were only rudimentary tools to compose independently developed pieces of software.
With procedural languages, small, encapsulated units of code called procedures were introduced with standardized calling
conventions, making separate compilation possible. In addition these procedures could now be ported to all other computer platforms
that had a compiler for this language. However, procedures were too fine-grained entities to be distributed and reused independently.
Procedures often depend on definitions of data types and on other procedures but these dependencies are implicit, buried in their
encapsulated implementation. It would be a lot of work for an application builder to take hundreds of packages containing single procedures and
compose. For this reason procedures had to be grouped in large libraries.

Then came object-oriented programming encapsulating data structures and procedures behind well defined interfaces. It was thought that
objects would revolutionize reuse by allowing one to build an application entirely out of pre-defined, loosely coupled, objects. 
Object orientation was indeed very successful and objects such as supported by most programming languages can be used to model
entities going from the granularity of employee records to huge subsystems. But it is precisely this lack of syntactical distinction and
of distinct tooling support that makes it difficult to use objects as units of third-party reuse and composition. Normally the programmer is
free to randomly assign class definitions to modules and there is no way of expressing expressing the dependencies between subsystems
at a higher level than module dependencies that are resolved by the linker.

This was a very unsatisfactory state of affairs as concepts from object orientation such as separation of interface and implementation
and Liskov's substitution principle fitted perfectly into McIlroy's vision of software components \cite{Liskov}. Thus in the 1990's several attempts
were made to create software components building in the ideas of software modules and object orientation. In the remainder of this
chapter we will first go through the definitions of modules in section \ref{sec:modules}, and services in section \ref{sec:services}
to establish them as basic constructs that can be used to build component standards. Libraries are covered in \ref{sec:libraries}
as they share the primordial motivation of software reuse but are an essentially different concept. The chapter ends with section
\ref{sec:components} covering modern definitions of software components and presenting some of the most important component
technologies available.


\section{Modules}
\label{sec:modules}

Modules make it possible to partition a program into smaller parts that can be developed independently and assembled.
A good description of the motivation for modular programming can be found in Parnas \cite{Parnas}

\begin{quotation}
``The benefits expected of modular programming are:
(1) managerial - development time should be shortened because separate groups would work on each module with little need for communication;
(2) product flexibility - it should be possible to make drastic changes to one module without a need to change others;
(3) comprehensibility - it should be possible to study the system one module at a time. The whole system can therefore be better designed because it is better understood.''
\end{quotation}

Although this lucidly states why modules are important, it doesn't really describe what they are. Perhaps the most complete
definition was given by Kirk Knoernschild \cite{Knoernschild}:

\begin{quotation}
``A module is a deployable, manageable, natively reusable, composable, stateless unit of software that provides a concise interface to consumers''
\end{quotation}

Modules are deployable because they are physical packages of code. The details vary depending on the programming language but modules are
always meant for local loading into a process and therefore come in a format that is understood by the machine or interpreter that is
executing the process. This is what is meant by native use. They are stateless because they are just the binary representation of the
code that is brought to life during execution. In a way, modules are the persistent storage equivalent of the read-only instruction
memory space of the Harvard architecture.

But the most important aspect of modules is that they are composable, providing a mechanism to delay the binding of entities to its consumers
to a point in time after the compilation is finished. As Szyperski \cite{Szyperski} put it,

\begin{quotation}
``An important hallmark of truly modular approaches is the support of separate compilation, including the ability
to type-check across module boundaries properly.'' %Szyperski pg 39.
\end{quotation}

This is possible precisely because modules provide the specification of an interface that instructs the compiler how an entity must be used. As long
as the compiler generates code that follows this usage specification, the actual linking need only be done when these entities are actually required
during execution.

Because modules can be composed after their compilation, they can be developed by independent teams as long as their interface doesn't change.
This also makes modules an important managerial tool to partition the development of a software product,

An important consequence of the separation of compilation units is that the same module can be used to build different software products if it's
contents are useful in more than one context. This feature makes modules the basic unit of native reuse. 

It is easy to extend the meaning of the term module to include concepts such as components or objects but this overly broad concept
would only lead to confusion and to a lack of precision of our definitions. Indeed, as Szyperski noted, ``...modules can be used, and
always have been used, to package multiple entities, such as ADTs or, indeed, classes, into one unit. Also modules do not have a concept
of instantiation, whereas classes do''

Modules in \texttt{C/C++} are object files, static or dynamic libraries and executables. In Java modules are represented by the JAR file format and
its variants, WAR and EAR files. The problem with Java modules is that they provide no truly effective mechanisms of encapsulation. All classes, even
internal implementation classes in the \texttt{classpath} are globally visible. In addition it is difficult to trace dependencies between JAR files
because classes can refer to any other class visible in this global name space. The \texttt{OSGi} framework was created to remedy this situation,
enforcing visibility restrictions and managing the dependencies on a JAR file level \cite{Hall}.


% pesquisar modula-2 ?

%Modules are used to encapsulate design decisions. Repository mining can be used to find out where bad modularization causes changes in one
%module to propagate to others. % isso Ã© relevante?


\section{Libraries}
\label{sec:libraries}

A library is a stateless collection of reusable, fine-grained entities such as procedures and classes, packaged in a single module. These entities could be reused
and delivered individually but the cost of managing a high number of modules would be too high. The use of libraries is always local and intra-process using the linking
mechanism of modules.

Libraries allow a separation of interface and implementation, the former usually called \emph{Application Programming Interface} (\texttt{API}). There are many examples
of a standardized \texttt{APIs} that have many implementations such as the \texttt{OpenGL} graphics library. To a certain extent, libraries enable late-binding but not
as much as object-oriented polymorphism would allow. Programs don't usually select a specific version of a library at runtime and its not possible to load more than
one implementation of a library at once. In addition libraries are only replaceable without recompilation of its clients if their binary interface, also called
\emph{Application Binary Interface} (\texttt{ABI}), remains the same despite internal differences. Libraries are also stateless, it would make no sense to load a library
more than once in the same process. There are no instances of libraries.

In general, the procedures or classes in a library are not randomly thrown together. They are assembled in one package because they all deal with the same problem domain.
Libraries are most successfully employed to achieve code reuse across horizontal domains. Most widely used libraries address problems that are common to many applications.
For example, the \texttt{BLAS} linear algebra package, the \texttt{Hibernate} library and the \texttt{Qt} windowing library are used in many different context because they
contain infrastructure code that is independent of any specific application domain. In contrast, it is difficult to see libraries that contain a generic class modeling employees
because each organization is likely to have different requirements for such a class.

Libraries are a natural consequence of modules and separate compilation and appeared mostly at the same time. Because the same collection of horizontal utilities
could be used in many applications in the same system, it made sense to install pre-compiled modules.

\section{Services}
\label{sec:services}

The notion of a service incorporates a pattern of control flow. A service is always reactive, responding to requests of a client process. In some cases
services can call a client using a callback mechanism, but the initiator of the dialogue is always the client. An essential property of services is a
separation of interface and implementation akin to polymorphism in object oriented languages. A service is a runtime entity and has its own identity.
The same process can use several individual services that implement the same interface. For example a process could read files from different file
servers, all providing the same set of operations.

Although in some cases it is convenient to use the term service to describe an object or an architectural unit within a process that is used in
a reactive manner, we will add two more requirements to our definition of service to prevent unnecessary confusion.

The first requirement is that a service should be accessible through some form of inter-process communication (IPC). For example a local printing service
could be invoked by placing the documents to print in a certain location in the filesystem. The second requirement is that any individual service
should have a location transparent identifier, an URL.

These two requirements allow us to establish services as a primary form of inter-process code reuse. Services are deployed only once and can be used
by many clients within an organization.

Services are particularly useful as building blocks of large enterprise systems where procedures must follow work flows that involve retrieving data
from a centralized database system, billing external organizations and so on. The individual services are in many cases re-used in more than one
application. For example, the employee database service could be consulted both by a human resources application or an accounting application.
This kind of architecture is known as \emph{Service Oriented Architecture (SOA)}.

Due to the cost of \texttt{IPC} operations, services tend to provide coarse grained operations that do a lot of work to compensate for the invocation
overhead.

Although our definition allows any \texttt{IPC} mechanism to be used, in this discussion whenever we use the term service we will be referring to
services accessible using a \emph{Remote Procedure Call (RPC)} or \emph{Remote Method Invocation (RMI)} abstraction.

Despite being conceptually unrelated, services are necessarily packaged and deployed using modules and this has important consequences on the
reusability of services. If more than one service implementation is packaged in the same module, one cannot be used without including the other
and its dependencies. Also if a service is called through \texttt{RMI} the interface classes cannot be put in the same module as the implementation
as this would force clients to depend on the module of a specific implementation, even if they use another one.

% Services have to be coarse grained and specific to be both useful and efficient. But it makes them less reusable.
% Classes cannot be used directly as units to reuse the code of a service because they are not units of deployment.
% Code reuse of a service can only be achieved if it is designed in a modular way

\section{Components}
\label{sec:components}

Before we begin to attempt any definition of what components are, we will try to make the point that something is still missing in the
landscape of code reuse.

\begin{enumerate}
 \item Modules are just containers of code
 \item Objects are too fine grained units of reuse
 \item Objects are not units of deployment, they are not physical entities.
 \item Dependencies between classes and procedures are mostly implicit
\end{enumerate}

Intuitively, what is needed is a concept that denotes a unit of both physical and logical design. We will call those units \emph{software components}.
As is the case with other many other concepts, the term \emph{software component} means slightly different things to different people. Perhaps the
most general definition, that encompasses the core notions behind components, is the one given by Grady Booch \cite{Booch87}:

\begin{quotation}
``A reusable software component is a logically cohesive, loosely coupled module that denotes a single abstraction''
\end{quotation}

A point of contention is the moment when the actual phase of composition takes place. Several authors view components as reusable source entities that
are integrated at build-time (at build-time there is no difference if the components are in source form or already in module form) \cite{Lakos}, some
insist that components should be assembled only at runtime \cite{Szyperski} \cite{Heineman} and others feel that it is not worth to make this distinction
\cite{Czarnecki00} \cite{Sametinger}.

Although we feel personally more inclined to accept a more general definition of components, in this text we will use the one by Szyperski and Pfisters \cite{WCOP97}

\begin{quotation}
``A Software component is a unit of composition with contractually specified interfaces and explicit context dependencies only.
A software component can be deployed independently and is subject to composition by third parties.''
\end{quotation}

Even with all these carefully crafted definitions the distinction between modules and components can become blurry if
we do no take care to insist that a component should be a logically cohesive unit, in other words, it should contain
a single abstraction. Without this requirement what remains is a specification for modules that are composed at runtime 
as exemplified by the following definition of \texttt{OSGi} modules: \cite{Hall}

\begin{quotation}
``\textbf{Module} A set of logically encapsulated implementation classes, an optional public \texttt{API} based on a subset
of the implementation classes, and a set of dependencies on external code.''
\end{quotation}

Although this definition agrees with most things we have said about components, the difference, of course, is that modules
are not required to contain code for a single unit of functionality. An \texttt{OSGi} module can be a loose collection of
classes, a library indeed, if it explicitly specifies what classes are part of its public \texttt{API} and on which other
modules it depends. As a matter of fact, \texttt{OSGi} has been used as an infrastructure for component frameworks in \texttt{Java}.

In addition, to be independently deployable, a component cannot be physically integrated in a larger software product at build-time,
it must remain independent and be composed at runtime. This requirement means that to support composition we cannot rely on the
mechanisms provided by the compiler and the linker to check dependencies and compose modules. We must establish rules to reify these
dependencies and make components programmatically composable at runtime. 

First we require that the interaction between two connected components should happen through a well defined interface.
For component orientation to make sense at all, it should be possible to exchange a component in an application by another
one that has the same interface but a different implementation. In other words, components should follow Liskov's
Substitution Principle \cite{Liskov}.

If the interaction is based on method calls there should be an abstract interface type that is implemented by the component responding
to method calls and known to the requesting component. If the interaction is based on streams of data, it should follow a protocol
that is known to both parties and to the external agent responsible for the composition.

The points of connection between components are called \emph{ports} and can be of two kinds. The first kind are ports used to
get access to a service that is provided by the component. The second kind is used by the component to interact with services
it depends on. We will adopt \texttt{CCM}'s nomenclature and use the terms \emph{facet} and and \emph{receptacle} for
``provides'' and ``requires'' ports respectively \cite{CCM}. The general idea is that one component is connected to the other
by connecting a facet to a receptacle. Ports are always associated to an interface.

Although the general idea of these rules is simple, there are many ways of implementing them. The languages used to implement
components, the form of interaction, how interfaces are represented and implemented: for every one of those details there
are many possible choices of implementation. At the same time, it is essential that components conform to the same set of
rules to be able to interact. A set of these rules is called a \emph{component model}. This model implicitly defines an abstract
platform or environment suitable for executing these components. We will use the term \emph{component framework} for the
implementation of such a model.

These ideas are captured more precisely in the following definition by Council and Heineman \cite{Heineman}:

\begin{quotation}
``A software component is a software element that conforms to a component model and can be independently deployed and composed
without modification according to a composition standard.

A component model defines specific interaction and composition standards. A component model implementation is the dedicated
set of executable software elements required to support the execution of components that conform to the model.

A software component infrastructure is a set of interacting software components designed to ensure that a software system
or subsystem constructed using those components and interfaces will satisfy clearly defined performance specifications.''
\end{quotation}

An interesting example that predates the modern definition of software components and component model are \texttt{UNIX}
\emph{pipes and filters}. Filters are programs that communicate by streams of text data, while pipes are channels through
which the output of one filter can be directed to the input of another one. It is common to use program such as the \texttt{sed}
stream editor to adapt a streams content to the input protocol of another one. To construct more advanced behaviors \texttt{shell}
command languages are commonly used as glue language. In addition the individual filter programs are perfectly self-contained,
independently deployable and perform well defined tasks. The component infrastructure is the \texttt{UNIX} operating system itself.

However most of the ``canonical'' component models interact using object-oriented approaches. Interfaces are expressed as abstract
base classes and components represent their facets as objects that implement these interface. Conversely, a receptacle
receive a reference to an object implementing the interface it expects and is then able to use it by the means of method calls.
In the case of intra-process components, a connection can be established by means of a reference to the facet object.
When \texttt{RMI} is used, the receptacle receives a reference to a \emph{stub} object that forwards the calls across an \texttt{IPC} channel. 

Local component frameworks are little more than a set of infrastructure utilities that perform the loading of components and their composition.
Remote component frameworks are typically more heavyweight including implementations for one or more \texttt{RMI} protocols, component registries
and so forth. Some framework go to the point of providing an entire environment that includes persistence and distributed transactions support.

Perhaps the most prominent example of a local component framework is \texttt{Microsoft's} \texttt{Component Object Model (COM)}, although
later remote components were introduced. At its core is a specification for binary interfaces. An interface is represented as a table of
pointers to methods. A facet is an object whose binary representation has a pointer to the method table representing its implemented interfaces.
It is not by chance that this scheme is precisely how Microsoft's \texttt{C++} compiler lays out polymorphic objects in memory.
In \texttt{COM} every facet has to implement the interface \texttt{IUnknown} that contains methods for reference counting and a method
to obtain reference to other interfaces implemented by this component. In \texttt{COM} interface and components are identified by
universally unique identifiers (UUID), 128-bit random numbers generated in a way to make clashing extremely unlikely.
When components are installed, factory objects are registered in a system registry using the component's UUID as a key.
When a program needs the functionality of a specific component, it locates a factory using this registry and instantiates the desired component.
The same mechanism is used for components that depend on other components, which means that component dependencies are not explicit
in \texttt{COM}. \texttt{COM} was the infrastructure used for the \texttt{Object Linking and Embedding (OLE)} technology that enables
things such as editing rich text using a word processor component inside a spreadsheet cell. \texttt{COM} is still being used
in a variety of services in Microsoft's operating system but is largely being superseded by the \texttt{.NET} framework for application
programming. Nonetheless, has influenced many other component frameworks like Mozilla's \texttt{XPCOM} and \texttt{OpenCOM}, a component
framework for embedded applications \cite{XPCOM} \cite{OpenCOM01}.

Another good example of local components are Sun's JavaBeans technology. There are several component models supported by the Java platform, each
suited to a particular problem domain. JavaBeans are visual components that can be composed and configured in a visual development environment
to produce user interfaces. JavaBeans can be configured by changing the values of their properties, which, by convention are accessed by \emph{getter}
and \emph{setter} methods. JavaBeans can be sources or consumers of events and thus can be connected to each other. 

Sun's component frameworks are all based on the Java language and depend heavily on features of the JVM. The packaging of all Java components is
done using Java archive (JAR) files, that basically are compressed files containing class files and resources.

For the enterprise market, Sun introduced the Enterprise Java Beans (EJB) component framework. This specification includes several kinds of beans,
but the most important ones are the so-called session beans. Session beans are service components that run on an application server that provide
all the infrastructure needed to enable remote access using \texttt{Java RMI}. The EJB platform also includes directory, messaging, persistence and
transaction support services. The session beans model is not connection oriented. A bean that depends on other beans has to go through the
directory service to get a reference to the desired bean.

In addition to JavaBeans and EJB beans, there is the Java servlet specification. Java servlets are components that contain an implementation
of a server for some protocol, usually HTTP. Java servlets are usually packaged in WAR files, which are an extension to the JAR format
with a pre-defined standardized structure for the laying out web applications. These WAR files can be deployed directly in an application server.

The CORBA Component Model (CCM) is OMG's response to EJB and proposes a language-independent component model, compatible with EJB. CCM is built
on top of CORBA, a language independent standard for remote objects and remote method invocation \cite{CCM}. CCM extends CORBA's interface definition language
(IDL) to include the concept of component connectors such as facets and receptacles. Unlike EJB and COM, by enforcing explicit receptacles, support
a connection-oriented style of composition.

In the past two decades, with the success of object-oriented
programming, remote method invocation (\texttt{RMI}) has proven itself an effective way of building
distributed systems. Even if inherent characteristics of remote communication cannot be made totally
transparent \cite{Kendall}, remote method invocation is a powerful abstraction because it is easy to
reason about. Applying the same object-oriented methodology across process boundaries, the programmer
can effectively think about his application as a set of interacting objects at all levels.

Unsurprisingly, there are many different and incompatible middleware platforms based on \texttt{RMI}.
They differ in communication protocol and secondary services they offer, but core functionality is mostly
the same. Many applications would be equally well served by several \texttt{RMI} implementations and
ideally they could be portable between them. Like everything else, middleware platforms are subject to
change over time, and may prevail or disappear over time. Being portable is, consequently, a matter of
minimizing the risk of being stuck with an abandoned middleware. Portability also ensures that a piece
of software can be reused independently in other contexts.

While portability is mostly a long-term concern, the incompatibility of middleware platforms introduces
the more immediate problem of interoperability. Heavy-weight dependencies frequently pose a problem
for effective software reuse and with distributed objects this is even more so. Distributed objects are supported
by a communication infrastructure and, therefore, their interoperability is limited to software built using the
same protocol. In fact, it is interesting to note that some middleware platforms impose such a strong coupling of objects to
their \texttt{API} that it becomes difficult to call methods in the same process without using the remote communication stack.

To relieve the problem of interoperability several solutions involving the translation of messages have been
proposed. The simplest solution is to forward messages for a specific object. For example, a \texttt{SOAP} front-end can
be created for a specific \texttt{CORBA} object \cite{soap, corba}. A more general approach is to translate the messages transparently
from one middleware protocol to another. As more middleware protocols are added, however, the number of translators
needed rises quadratically. To address this problem, some solutions translate all messages to an intermediate format,
which must be a functional subset of all supported formats, at the expense of expressivity \cite{Flores, Issarny, Bennaceur, Bromberg, Nakazawa}. While these solutions
are certainly needed for the integration of legacy systems, they don`t address the source of the interoperability
problem which is the tight coupling that most middleware platforms impose on distributed applications. If applications were
easily portable between middlewares, then is would also be easy to open ports using several different communication
protocols, reducing the need of message translation solutions.

The recommended solution in software engineering is to build layers to insulate
the application code from third-party libraries that could become an undesirable dependency \cite{Sommerville}.
Building such a layer, however, is often too labour-intensive and cannot realistically be expected from programmers
who already struggle with short deadlines to deliver the code that really matters, which is the application code.
Ideally, the insulation layer would be generated automatically, and in fact it should not be too difficult. In order
to un-marshal the arguments and call a method, the middleware only needs to know the method`s signature. On the
other hand, the client could be independent of middleware if it called the remote object through an abstract
interface. If the application was built using interface-based programming, \cite{Pugh} the interfaces could naturally
be used by the middleware to set up the client and server stubs. like in \texttt{\texttt{Java} \texttt{RMI}}. The client stub would
implement this interface and the server stub would call an user-supplied object that implements this same interface.

The other problem left to solve is how a client would locate the right server object without resorting to middleware-specific \texttt{API}s.
The answer is that it should not have to. Actively searching for services simply cannot be done in a platform-independent way.
Applying the principle of dependency injection \cite{Fowler2} the client simply declares that it depends on a service implementing
a certain interface and during the configuration phase it is supplied with a reference to a conforming service. In other words,
the concern of composition and configuration is removed from application code.

Actually there is a middleware platform that separates the concerns of communication protocols and other infrastructures services
in the way we have described. It is the \texttt{Java} implementation of the Service Component
Architecture (\texttt{SCA}). An \texttt{SCA} application server reads a configuration file that states how services are to be configured
and connected. The \texttt{RMI} technology used to connect the objects can be configured explicitly and can be changed without requiring
changes to application objects. Unfortunately \texttt{SCA} for \texttt{Java} is an exception. The specification of \texttt{SCA} for C++, for example,
ties distributed objects to its own \texttt{API}. The \texttt{RMI} protocol can be changed at will, but the code is no longer truly portable.
While \texttt{Java} is well-suited for many applications, native code might be better for situations where execution speed or fast response
times are required.

As Al-Gahmi and Cook \cite{Al-Gahmi}, we think that the difference in flexibility and ease of development in native languages is
exacerbated by the lack of new developments in tools and runtime infrastructure during the 2000s. The reason is that managed
languages such as \texttt{Java}, \texttt{C\#} and \texttt{Python}, that focus on flexibility and programmer productivity
have been favored over traditional native languages such as \texttt{C} and \texttt{C++}. \footnote{We adopt the terms \emph{native}
and \emph{managed} languages as they capture more accurately the essence of the difference between languages like \texttt{C++} and
\texttt{C\#}}According to Sutter \cite{CPPAndBeyond2011}, this has been possible because during the period from 90s to the mid 2000s
the only really widespread kind of computer was the personal computer. Also during this time hardware performance kept increasing.
However, in the last few years, there has been dramatic change on two fronts: mobile computing and servers.

With the introduction of smartphones and tablets, new ways of user interaction have been made possible such as augmented reality \cite{Petter,Sulisz,Jung,Bauset,Ha}. Some of
these applications are very \texttt{CPU}-intensive and some require short response times in order to be useful. Clearly, these applications are in
direct conflict with the general goal of preserving battery life. Therefore, the best possible performance per watt becomes essential
and this is something dynamic languages cannot offer. Initially, several of the most popular smartphone platforms supported only applications
written in managed languages, such as \texttt{Java} or \texttt{C\#}. However, the second generation of these platforms is now supporting native applications,
which means applications written in C and \texttt{C++}.

Moreover, with the explosion of web-based applications and cloud computing, significant demand has been placed on the server infrastructure.
Most of these applications are supported by huge server farms which consume equally huge amounts of power. According to Hamilton, \cite{Hamilton}
88\% of a datacenter's cost is directly related to hardware and power expenses. Therefore, it becomes essential to maximize the performance per watt ratio.
Facebook, for example has developed a PHP to \texttt{C++} compiler, \texttt{HipHop} \cite{HipHop}, in order to meet the increasing performance demands.
According to Facebook engineers, with \texttt{HipHop}, the same workload can be handled with a 50\% reduction in \texttt{CPU} usage in comparison to PHP.
Another benefit is that, if a server farm requires less power consumption for the same functionality, it is also better for the environment.

An interesting project that confirms the need for more performance and low-level access to the operating system is Google's Native Client \cite{NaCl}.
The Native Client is an infrastructure embedded in Google's Chrome browser to enable the execution of \texttt{x86}, \texttt{x86-64} and \texttt{ARM}
native code on the client's machine. The motivations behind this project are better performance and integration with local resources like graphics and audio. This infrastructure
forces the developer to provide one version of his application for each hardware platform, but there is a research project at Google called the Portable
Native Client \cite{pNaCl} that proposes to deliver the executables in the form of \texttt{LLVM} bytecode. This bytecode is then locally converted by LLVM to native bytecode.

In addition to these questions, there is another change that is worth pointing out. The shift to multi-core architectures means that the speed of
execution of sequential code is now effectively limited, at least for the next years. While many important algorithms and applications can be
paralelized efficiently on current hardware, many algorithms are inherently serial or can't be run efficiently in parallel \cite{Madriles}.
For these applications the performance per cycle will be absolutely essential.

Of course, managed languages have seen tremendous improvements in performance, using just-in-time compilation (JIT) \cite{Aycock}. But the
addition to Java's standard library of facilities to directly manage memory buffers confirms that to extract even more performance out of
these languages it is necessary to fight against the overhead imposed by an interpreter that hides the hardware too much.
Indeed, memory access is a critical performance issue. JIT compilation can significantly improve CPU intensive micro-benchmarks,
in managed languages making them competitive with native languages in this aspect, but efficient memory access is inherently
inefficient in languages where relationships between objects are restricted to references. In \texttt{C++}, in contrast,
the programmer objects can contain other objects directly giving the programmer control of the memory layout of objects.

In the past years we have seen huge improvements in processor speed but the RAM access speed has increased at
a smaller rate. To counter this problem modern processors typically have three levels of cache to increase
memory access operation. Although caching improves performance, it also makes it very sensitive to the memory
layout of data structures. High performance data structures have to maximize cache hits making use of
pre-fetching of cache lines. In \texttt{C++} an array of objects can be allocated in a single continuous chunk of memory
and the traversal is very efficient. However, in \texttt{Java} an array is a chunk of memory with pointers to
many other memory locations, making the traversal very inefficient in terms of cache hits. The effects of
using a single buffer instead of several linked ones are demonstrated in the work of Häubl and colleagues who
modified a \texttt{Java} virtual machine to merge the meta-data and character array components of the class
\texttt{java.lang.String} achieving a considerable speed-up.

Even worse is that multi-core processors have separate level-one caches for each core. Every time a
core updates a memory location the other caches must be updated if they are caching this same location, causing
memory access stalls. Because cache lines contain several words, it can happen that two cores update
different memory locations that happen to fall into the same cache unit. When this happens, both caches
are constantly synchronized causing considerable slowdown. This is called \emph{false sharing} and must
be avoided at all costs to allow the cores to run independently at full speed.

By denying programmers the possibility to fine-tune the memory layout of their data structures,
higher-level languages can impose a significant performance overhead. To complicate matters, some virtual machines
employ a technique called heap compaction \cite{Clarke}, that on one hand makes the program more space-efficient, but can
cause false-sharing of variables that were previously independent.

These languages also require a more sophisticated infrastructure that can make them unsuitable for embedded devices.
When more control is needed languages closer to the hardware have to be employed at the expense
of flexibility and programmer productivity.

Of course, choosing a language is an engineering trade-off. Often it is cheaper to maximize programmer
productivity. The problem is that today's low-level programming languages are more complicated than
strictly necessary. Basically today the options are pure \texttt{C} or \texttt{C++}. \texttt{Fortran}
and \texttt{Objective-C} are also important native languages but are more restricted to specific markets.
Google's \texttt{Go} language has still to get a more widespread adoption. While \texttt{C} is very
successful as a ``high-level assembler'', it has no support for object-oriented programming and therefore
is not very suitable for component-based development. \texttt{C++} on the other hand supports programming
at a higher level of abstraction but suffers from several problems such as a very convoluted syntax that
makes it difficult to develop tooling and represents a steep learning curve. In addition it has no complete
introspection support. Although the language can be difficult to master, the primary reason why it is difficult
to develop reusable components in C++ is because the language encourages a strong coupling of application code
to infrastructure \texttt{APIs}. Due to the difficulty of tool development and the lack of introspection
it is easier for framework developers to leave the development of glue code to the application
programmer. To save time this glue code is usually tangled with application code instead of being an insulating
layer. The result is that software in \texttt{C++} is usually tightly coupled to the infrastructure. In other languages
such as \texttt{Java}, techniques relying on introspection make it possible to develop frameworks that adapt
themselves to the business code instead of the other way around. The result is that business code can be kept
clean of references to infrastructure code resulting on components that are portable between different frameworks and more reusable.

The present work attempts to improve the situation of \texttt{C++} component development by providing a portable
introspection support on which non-invasive frameworks can be based. In 2011, a new \texttt{C++} standard was published
\cite{CPP11} providing a few new features that were essential in the development of this introspection library.
With this introspection framework we have developed a component container that supports the composition and configuration
of components without requiring components to be explicitly developed for it. This container is base on an existing
open-source implementation of \texttt{SCA} for \texttt{C++} which we extended to make component development as easy to use and as
flexible as the Java version.

The contributions of this dissertation are a type-safe, standards conforming and non-intrusive reflection framework for \texttt{C++} and
an extension of a Service Component Architecture implementation for \texttt{C++} to support dependency injection. In addition this
dissertation contains an extended discussion of the dependency injection principle and its consequences on source code and 
package design. As dependency injection was conceived by industry developers to simplify software composition there are few
formal sources discussing it. Indeed, the most cited source on dependency injection is Martin Fowler's personal web page.

This work is organized as follows: In chapter \ref{chap:components} we discuss forms of software reuse and establish components
as coarse-grained units that are self-contained both logically and and in terms of packaging. In chapter \ref{chap:ioc} we discuss the dependency
injection principle and its relevance for building applications out of software components. We conclude this chapter by pointing
out the necessity of computational introspection for the implementation of this principle. Chapter \ref{chap:reflection} discusses
the history of computation reflection and introspection, and in particular the importance as the basis for meta-programming in
strongly-typed languages as Java. The remainder of this chapter is dedicated to introduce the introspection support that we
have designed. In chapter \ref{chap:sca} we describe the Service Component Architecture component model and how its use
of dependency injection in languages with introspection support decouples components from the infrastructure consequently making
them more reusable. We then proceed to show how we used our introspection framework to support dependency injection of
native components written in C++, and what the consequences on source code are. And finally in chapter \ref{chap:conclusion} we
conclude with a few thoughts about the relations of our work with others and about future directions.